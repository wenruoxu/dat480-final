# CAM 与 DCAM 设计概述

## CAM 的定义

内容可寻址存储器（Content Addressable Memory，CAM）是一种以“内容”而非“地址”作为访问依据的存储结构。在 CAM 中，输入的数据会同时与存储单元中的所有条目进行并行比较，当某一条目与输入内容完全匹配时，系统立即给出命中信号。由于这种“全并行比较”的特性，CAM 非常适合用于需要高速匹配的应用场景，例如网络包检测、路由查找以及入侵检测系统中的模式匹配。

在网络深度包检测（DPI）中，CAM 通常用于将连续输入的数据流与大量已知的固定字符串模式进行比较。每一个模式由若干连续字符构成，CAM 通过滑动窗口的方式，对数据流中的每一个可能对齐位置进行匹配判断，从而检测是否出现攻击特征或违规内容。

## 传统 CAM 在 FPGA 实现中的问题

尽管 CAM 在概念上非常适合高速匹配任务，但在 FPGA 上直接实现传统 CAM 结构会暴露出明显的问题。首先，传统 CAM 的实现方式通常要求对输入字符与模式字符进行逐字符比较，这意味着每一个模式都需要独立的字符比较逻辑。当模式数量达到成千上万时，这种比较逻辑会被大量重复实例化，导致逻辑资源消耗迅速膨胀。

其次，传统 CAM 通常依赖多位宽移位寄存器来实现输入数据流的滑动窗口。例如在基于 ASCII 的场景中，移位寄存器往往是 8 位宽，这使得移位网络本身就成为一个资源和布线的重负。随着模式长度和并行度的提升，移位寄存器带来的面积和时序压力会进一步加剧。

此外，字符比较逻辑在不同模式之间高度冗余。对于同一个输入字符，例如字母 ‘A’，系统会在每一个相关模式中重复判断“是否等于 A”。这种重复比较不仅浪费 LUT 资源，也限制了整体结构的可扩展性，使得设计在频率和规模上都难以继续提升。

## DCAM 的设计思想

DCAM（Decoded CAM，也称 Pre-decoded CAM）正是针对上述问题提出的一种优化结构。DCAM 的核心思想是将“字符是否相等”的比较操作从每一个模式中抽离出来，集中放在输入端统一完成。换句话说，DCAM 不再让每个模式各自判断输入字符的取值，而是先对输入字符进行一次集中式解码，然后将解码结果以更简单的形式分发给所有模式。

在 DCAM 中，输入的 8 位字符首先进入一个字符解码器（Decoder）。该解码器并不输出完整的字符值，而是输出一组一位宽的比较结果信号，例如“是否等于 A”“是否等于 B”“是否等于 C”等。这些信号在一个时钟周期内同时产生，并被所有模式共享使用。这样一来，每种字符的比较逻辑只需要实现一次，大幅减少了重复硬件。

## DCAM 的结构与实现方式

在完成字符预解码之后，DCAM 利用 FPGA 中的移位寄存器资源对解码结果进行时间对齐。与传统 CAM 不同的是，DCAM 移位的对象不再是 8 位字符数据，而是 1 位的解码信号。这使得移位结构的位宽从 8 位缩减到 1 位，显著降低了资源消耗和布线复杂度。

在 Xilinx FPGA 中，这一功能通常通过 SRL16 原语实现。SRL16 是一种由查找表构成的可配置移位寄存器，能够在单个逻辑单元中实现最多 16 级的一位移位。DCAM 正是利用这一特性，将不同字符位置的解码信号延迟适当的周期，使它们在同一时刻对齐，从而对应模式中不同字符的位置关系。

当所有与某一模式相关的解码信号在同一时钟周期内同时为有效状态时，模式匹配逻辑便会产生命中信号。这一逻辑通常只需要简单的与运算即可完成，因此非常适合做成细粒度流水线结构。通过将每一级逻辑限制在单层 LUT 加寄存器的范围内，DCAM 可以实现很高的工作频率。

## DCAM 的并行性与性能优势

DCAM 的结构天然支持高度并行。一方面，所有模式可以同时进行匹配判断；另一方面，通过复制解码和移位结构，还可以在一个时钟周期内处理多个输入字节。随着并行度的提升，系统吞吐率可以近似线性增长，而不需要引入复杂的控制逻辑。

实验结果表明，在较早的 FPGA 工艺（如 Virtex-II）上，DCAM 就已经能够实现 2.5 到 10 Gbps 的处理吞吐率，而单位字符所消耗的逻辑资源仅为传统方法的一小部分。相比软件实现仅能达到数百 Mbps 的水平，DCAM 在性能和能效上都体现出可重构计算在特定应用场景中的显著优势。

## 小结

总体而言，DCAM 通过“预解码 + 一位移位”的方式，从结构层面解决了传统 CAM 在 FPGA 上资源冗余大、扩展性差的问题。它并不是一个通用意义上的最优存储结构，而是针对高速流数据模式匹配这一特定问题进行深度定制的结果。这种设计思路也正是可重构计算的核心价值所在：不是追求通用性，而是在明确应用特征的前提下，用硬件结构换取数量级的性能提升。
